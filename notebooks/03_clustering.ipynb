{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import plotly.express as px\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clustering by physical attributes",
   "id": "d5b81af6438574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "phys_feat_df = pd.read_parquet(\"../data/processed/physical_feat.parquet\")\n",
    "\n",
    "# ------------------------ Select the physical features ------------------------\n",
    "phys_cols = [\n",
    "    \"ks_objem\", \"ks_hmotnost_brutto\", \"ks_sirka\", \"longest_side\",\n",
    "    \"is_bulky\", \"is_heavy\", \"missing_carton_info\", \"missing_display_info\"\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------- Prepare feature matrix ------------------------\n",
    "X = phys_feat_df[phys_cols].copy()\n",
    "X = X.fillna(0)\n",
    "\n",
    "# ----------------------- Scale features --------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ----------------------- Clustering -----------------------\n",
    "k = 4\n",
    "km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters = km.fit_predict(X_scaled)\n",
    "phys_feat_df[\"cluster_phys\"] = clusters\n",
    "\n",
    "# ----------------------- Analyze clusters -----------------------\n",
    "cluster_stats = (\n",
    "    phys_feat_df.groupby(\"cluster_phys\")[\"total_time\"]\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .sort_values(\"total_time\", ascending=False)\n",
    ")\n",
    "print(cluster_stats)\n",
    "\n",
    "# ----------------------- Reduce the dimensions for visualization -----------------------\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=coords[:,0], y=coords[:,1], color=clusters.astype(str),\n",
    "    title=\"KMeans Clusters of Physical Features\",\n",
    "    labels={\"x\": \"PCA 1\", \"y\": \"PCA 2\", \"color\": \"Cluster\"}\n",
    ")\n",
    "fig.show()\n"
   ],
   "id": "ee91b23fde44b5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ----------------------- Elbow method to find optimal k ------------------------\n",
    "X_phys = phys_feat_df[\n",
    "    [\n",
    "        \"ks_objem\", \"ks_hmotnost_brutto\", \"ks_sirka\", \"ks_delka\", \"ks_vyska\",\n",
    "        \"longest_side\", \"is_bulky\", \"is_heavy\", \"density\", \"aspect_ratio\"\n",
    "    ]\n",
    "].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_phys)\n",
    "inertia = []\n",
    "K = range(2, 10)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=0, n_init=10)\n",
    "    km.fit(X_scaled)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "elbow_df = pd.DataFrame({\"k\": K, \"inertia\": inertia})\n",
    "\n",
    "fig = px.line(\n",
    "    elbow_df,\n",
    "    x=\"k\",\n",
    "    y=\"inertia\",\n",
    "    markers=True,\n",
    "    title=\"Elbow Method for Optimal k\",\n",
    "    labels={\"k\": \"Number of clusters (k)\", \"inertia\": \"Sum of squares\"},\n",
    ")\n",
    "fig.show()\n"
   ],
   "id": "6db6a468ee15b426",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%reset",
   "id": "9b58ba03f1c906cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clustering by location/branch",
   "id": "8dac1774e128eeda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ],
   "id": "4006508520e842f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "location_feat = pd.read_parquet(\"../data/processed/location_feat.parquet\")\n",
    "\n",
    "# ------------------------ Select the physical features ------------------------\n",
    "loc_feats = [\"pracoviste_kod\", \"umisteni_new\", \"umisteni_vyska\",\n",
    "             \"zcz_zpusob_zprac_kod\", \"trasa_kod\"]\n",
    "\n",
    "Xloc = location_feat[loc_feats].astype(\"category\")\n",
    "\n",
    "# ------------------------ One-hot encode ----------------------------------------\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "Xloc_ohe = enc.fit_transform(Xloc)\n",
    "\n",
    "# ----------------------- Clustering -----------------------\n",
    "k = 3\n",
    "km_loc = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "loc_clusters = km_loc.fit_predict(Xloc_ohe)\n",
    "location_feat[\"cluster_location\"] = loc_clusters\n",
    "\n",
    "# ----------------------- Analyze clusters -----------------------\n",
    "loc_stats = (\n",
    "    location_feat.groupby(\"cluster_location\")[\"total_time\"]\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .sort_values(\"total_time\", ascending=False)\n",
    ")\n",
    "print(loc_stats)\n",
    "\n",
    "fig = px.box(\n",
    "    location_feat,\n",
    "    x=\"cluster_location\",\n",
    "    y=\"total_time\",\n",
    "    points=\"outliers\",  # show individual slow/fast outliers\n",
    "    color=\"cluster_location\",\n",
    "    title=\"Distribution of Picking Time by Location Cluster\",\n",
    "    labels={\"total_time\": \"Picking time (minutes)\", \"cluster_location\": \"Cluster\"}\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "26129ffca52203d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%reset",
   "id": "9d977edd73515dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clustering by the operational workflow",
   "id": "233722a28ea235cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ],
   "id": "990244e1340123e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "worlkload_feat_df = pd.read_parquet(\"../data/processed/workload_feat.parquet\")\n",
    "\n",
    "# ----------------------- Select useful workload features -----------------------\n",
    "workload_feats = [\"workload_proxy\", \"log_weight\", \"time_per_item\", 'vaha_vyriz']\n",
    "\n",
    "Xwork = worlkload_feat_df[workload_feats].copy()\n",
    "\n",
    "# Drop missing values if any (or fill with median)\n",
    "Xwork = Xwork.fillna(Xwork.median())\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "Xwork_scaled = scaler.fit_transform(Xwork)\n",
    "\n",
    "# ----------------------- KMeans clustering -----------------------\n",
    "k = 3\n",
    "km_work = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "work_clusters = km_work.fit_predict(Xwork_scaled)\n",
    "worlkload_feat_df[\"cluster_workload\"] = work_clusters\n",
    "\n",
    "# ----------------------- Analyze median time per cluster -----------------------\n",
    "work_stats = (\n",
    "    worlkload_feat_df.groupby(\"cluster_workload\")[\"total_time\"]\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .sort_values(\"total_time\", ascending=False)\n",
    ")\n",
    "print(work_stats)\n",
    "\n",
    "# ----------------------- Plot boxplot of picking time per cluster -----------------------\n",
    "fig1 = px.box(\n",
    "    worlkload_feat_df,\n",
    "    x=\"cluster_workload\",\n",
    "    y=\"total_time\",\n",
    "    points=\"outliers\",\n",
    "    color=\"cluster_workload\",\n",
    "    title=\"Distribution of Picking Time by Workload Cluster\",\n",
    "    labels={\"total_time\": \"Picking time (minutes)\", \"cluster_workload\": \"Cluster\"}\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# ----------------------- PCA 2D scatter for visualization -----------------------\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(Xwork_scaled)\n",
    "\n",
    "fig2 = px.scatter(\n",
    "    x=coords[:,0],\n",
    "    y=coords[:,1],\n",
    "    color=worlkload_feat_df[\"cluster_workload\"].astype(str),\n",
    "    title=\"Workload Feature Clusters (PCA projection)\",\n",
    "    labels={\"x\": \"PCA 1\", \"y\": \"PCA 2\", \"color\": \"Cluster\"}\n",
    ")\n",
    "fig2.show()"
   ],
   "id": "3cc4c2a95d873e6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%reset",
   "id": "fd825f2b639a7ebb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Combined features: physical items attributes + workflow operations",
   "id": "771fa38213efbfb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ],
   "id": "b71edd3ad30229d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "phys_feat_df = pd.read_parquet(\"../data/processed/physical_feat.parquet\")\n",
    "worlkload_feat_df = pd.read_parquet(\"../data/processed/workload_feat.parquet\")\n",
    "\n",
    "phys_cols = [\n",
    "    \"ks_objem\", \"ks_hmotnost_brutto\", \"ks_sirka\", \"longest_side\",\n",
    "    \"is_bulky\", \"is_heavy\", \"missing_carton_info\", \"missing_display_info\"\n",
    "]\n",
    "workload_feats = [\"workload_proxy\", \"log_weight\", \"time_per_item\", 'vaha_vyriz']\n",
    "\n",
    "combined_df = phys_feat_df[phys_cols + ['cinnost_id']].merge(\n",
    "    worlkload_feat_df[workload_feats + ['cinnost_id', 'total_time']],\n",
    "    on=\"cinnost_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ------------------- Select features -------------------\n",
    "combined_feats = phys_cols + workload_feats\n",
    "\n",
    "X = combined_df[combined_feats].fillna(0)\n",
    "\n",
    "# ------------------- Standardize -------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------- KMeans clustering -------------------\n",
    "k = 3\n",
    "km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "combined_clusters = km.fit_predict(X_scaled)\n",
    "\n",
    "combined_df[\"cluster_phys_work\"] = combined_clusters\n",
    "\n",
    "# ------------------- Cluster summary -------------------\n",
    "summary = (\n",
    "    combined_df.groupby(\"cluster_phys_work\")[\"total_time\"]\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .sort_values(\"total_time\", ascending=False)\n",
    ")\n",
    "print(summary)\n",
    "\n",
    "# ------------------- PCA 2D visualization -------------------\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=coords[:, 0], y=coords[:, 1],\n",
    "    color=combined_df[\"cluster_phys_work\"].astype(str),\n",
    "    title=\"Combined Physical + Workload Feature Clusters (PCA projection)\",\n",
    "    labels={\"x\": \"PCA 1\", \"y\": \"PCA 2\", \"color\": \"Cluster\"}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# ------------------- Boxplot of time per cluster -------------------\n",
    "fig2 = px.box(\n",
    "    combined_df,\n",
    "    x=\"cluster_phys_work\",\n",
    "    y=\"total_time\",\n",
    "    points=\"outliers\",\n",
    "    color=\"cluster_phys_work\",\n",
    "    title=\"Distribution of Picking Time by Combined Clusters\",\n",
    "    labels={\"total_time\": \"Picking time (minutes)\", \"cluster_phys_work\": \"Cluster\"}\n",
    ")\n",
    "fig2.show()\n"
   ],
   "id": "2ebb0573e02a150f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%reset",
   "id": "680564249b0c4ee1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clustering by items hierarchy categories",
   "id": "dbfcd31374540f07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ],
   "id": "3e257ae42d586d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hierarchy_feats_df = pd.read_parquet(\"../data/processed/hierarchy_feat.parquet\")\n",
    "hierarchy_filtered = hierarchy_feats_df[hierarchy_feats_df[\"count\"] > 100].copy()\n",
    "\n",
    "Xh = hierarchy_filtered[[\"speed_median\", \"count\"]]\n",
    "scaler = StandardScaler()\n",
    "Xh_scaled = scaler.fit_transform(Xh)\n",
    "\n",
    "km = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "hierarchy_filtered[\"cluster_hierarchy\"] = km.fit_predict(Xh_scaled)\n",
    "\n",
    "fig = px.treemap(\n",
    "    hierarchy_filtered,\n",
    "    path=[\"hierarchie_lvl_1\", \"hierarchie_lvl_2\", \"hierarchie_lvl_3\",\n",
    "          \"hierarchie_lvl_4\", \"hierarchie_lvl_5\"],\n",
    "    values=\"count\",  # box size = number of operations\n",
    "    color=\"speed_median\",  # box color = median picking time\n",
    "    color_continuous_scale=\"RdYlGn_r\",  # green = fast, red = slow\n",
    "    title=\"Median Picking Time by Product Hierarchy\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(t=40, l=0, r=0, b=0)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    hierarchy_filtered,\n",
    "    path=[\"hierarchie_lvl_1\", \"hierarchie_lvl_2\", \"hierarchie_lvl_3\",\n",
    "          \"hierarchie_lvl_4\", \"hierarchie_lvl_5\"],\n",
    "    values=\"count\",  # box size = number of operations\n",
    "    color=\"cluster_hierarchy\",  # box color = median picking time\n",
    "    color_continuous_scale=\"RdYlGn_r\",  # green = fast, red = slow\n",
    "    title=\"Median Picking Time by Product Hierarchy\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(t=40, l=0, r=0, b=0)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(\n",
    "    hierarchy_filtered,\n",
    "    x=\"count\",\n",
    "    y=\"speed_median\",\n",
    "    color=\"cluster_hierarchy\",\n",
    "    size=\"count\",\n",
    "    hover_data=[\"hierarchie_lvl_1\", \"hierarchie_lvl_2\", \"hierarchie_lvl_3\"],\n",
    "    title=\"Hierarchy Categories by Speed & Frequency\",\n",
    "    labels={\"count\": \"Operation count\", \"speed_median\": \"Median time (minutes)\"}\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")  # log scale helps if some counts are huge\n",
    "fig.show()"
   ],
   "id": "39067a9d0c580b1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "15e8e474db921d20",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
